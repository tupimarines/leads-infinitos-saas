# Guia de Scraping em Produ√ß√£o: Evitando Bloqueios e Detec√ß√£o

Este guia consolida as melhores pr√°ticas para manter o scraper de Google Maps operando de forma confi√°vel em ambientes de produ√ß√£o, baseado nas t√©cnicas mais recentes de evas√£o de bots e "stealth scraping".

## 1. Camada de Navegador (Playwright)

### ‚úÖ J√° Implementado (N√≠vel B√°sico/Intermedi√°rio)
*   **User-Agent Falso**: Mascarar o User-Agent para parecer um navegador de usu√°rio real (Windows/Chrome).
*   **Client Hints (`sec-ch-ua`)**: For√ßar os cabe√ßalhos de baixa granularidade para bater com o User-Agent, evitando a discrep√¢ncia √≥bvia que causa bloqueios imediatos.
*   **Remo√ß√£o de Flags de Automa√ß√£o**: Uso de `--disable-blink-features=AutomationControlled` para esconder a flag `navigator.webdriver`.

### üöÄ Recomenda√ß√µes Avan√ßadas (Para Implementar se Bloqueios Voltarem)

1.  **Plugin de Stealth Dedicado**
    *   **Ferramenta**: `playwright-stealth` (Python)
    *   **Fun√ß√£o**: Aplica automaticamente dezenas de corre√ß√µes de fingerprint (WebGL, Console, plugins instalados, idiomas).
    *   **Como usar**:
        ```python
        from playwright_stealth import stealth_sync
        # ... dentro do loop do browser ...
        page = context.new_page()
        stealth_sync(page)
        ```

2.  **Rota√ß√£o de Viewport e Dispositivo**
    *   Em vez de usar sempre 1920x1080, varie ligeiramente as resolu√ß√µes ou emule dispositivos m√≥veis reais (iPhone, Pixel) rotativamente.
    *   O Playwright possui `playwright.devices['iPhone 13']`, que j√° configura User-Agent, Viewport e DPI corretos automaticamente.

3.  **Mouse e Intera√ß√£o Humana**
    *   O Google Maps rastreia movimentos de mouse. Clicar instantaneamente em coordenadas exatas √© suspeito.
    *   **Melhoria**: Adicionar pequenas curvas ou "overshoot" no movimento do mouse antes de clicar, e variar o tempo de digita√ß√£o (keystroke dynamics).

## 2. Camada de Rede (Infraestrutura)

Se o IP do servidor for marcado ("flagged"), nenhuma t√©cnica de c√≥digo vai resolver.

1.  **Proxies Residenciais Rotativos (Cr√≠tico para Escala)**
    *   IPs de Data Center (AWS, DigitalOcean, Azure) s√£o facilmente detectados pelo Google.
    *   Use servi√ßos como **Bright Data**, **Smartproxy** ou **Oxylabs**.
    *   Configure o Playwright para usar um proxy rotativo, garantindo que cada Job ou cada Sess√£o saia por um IP diferente.

2.  **TLS Fingerprinting (JA3)**
    *   Sistemas anti-bot analisam o "aperto de m√£o" SSL/TLS. O Playwright (baseado em Chrome) geralmente passa bem aqui, mas bibliotecas puras de Python como `requests` ou `aiohttp` geralmente falham. Continue usando navegadores reais.

## 3. Estrat√©gia Operacional

1.  **"Warm-up" de Sess√£o (Cookies)**
    *   Navegadores "frescos" (sem cookies) acessando diretamente endpoints profundos s√£o suspeitos.
    *   Acesse a home do Google, fa√ßa uma pesquisa aleat√≥ria, e *depois* v√° para o Maps. Isso gera um hist√≥rico de cookies mais leg√≠timo.

2.  **Limita√ß√£o de Taxa (Rate Limiting)**
    *   N√£o fa√ßa requisi√ß√µes t√£o r√°pido quanto o computador aguenta.
    *   Adicione um `random.sleep(2, 5)` entre a√ß√µes cr√≠ticas. √â mais lento, mas "lento √© suave, e suave √© r√°pido" (e n√£o bloqueia).

3.  **Monitoramento de "Soft Bans"**
    *   As vezes o Google n√£o d√° erro 403, apenas retorna resultados vazios ou dados gen√©ricos.
    *   Implemente verifica√ß√µes de "Sanity Check" no HTML retornado para garantir que os dados extra√≠dos fazem sentido antes de salvar.

## Resumo da A√ß√£o Corretiva Atual

No erro recente, o problema era **Discrep√¢ncia de Cabe√ßalho**: O navegador dizia ser "Chrome Windows" no User-Agent, mas "HeadlessChrome" nos detalhes t√©cnicos do protocolo HTTP (`sec-ch-ua`).

A corre√ß√£o aplicada no arquivo `main.py` sincronizou esses sinais.

**Se falhar novamente:** O pr√≥ximo passo l√≥gico √© integrar o pacote `playwright-stealth` e considerar o uso de proxies residenciais se o volume de requisi√ß√µes aumentar.
